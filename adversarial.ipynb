{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "project_directory = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_mnist_loaders(batch_size : int = 16, data_path : Path = None):\n",
    "    \"\"\"\n",
    "    Function to download MNIST dataset and return train- and test-loaders.\n",
    "    :param batch_size:\n",
    "    :param data_path: \n",
    "    \"\"\"\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = MNIST(root=data_path, train=True, download=True, transform=transform)\n",
    "    test_dataset = MNIST(root=data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = project_directory / \"data\"\n",
    "\n",
    "batch_size = 16\n",
    "train_loader, test_loader = get_mnist_loaders(batch_size, data_path)\n",
    "\n",
    "print(f\"{len(train_loader) * batch_size} train samples\")\n",
    "print(f\"{len(test_loader) * batch_size} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display images from the first batch of the test loader\n",
    "train_iterator = iter(train_loader)\n",
    "batch = next(train_iterator)\n",
    "\n",
    "def display_n_images(batch, num_to_display : int = 8):\n",
    "    images, labels = batch\n",
    "    fig, axes = plt.subplots(1, num_to_display, figsize=(12, 4))\n",
    "    for i in range(num_to_display):\n",
    "        image = transforms.ToPILImage()(images[i])  # Convert tensor to PIL Image\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"L: {labels[i].item()}\")\n",
    "    plt.show()\n",
    "\n",
    "display_n_images(batch, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(64*5*5, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = x.view(-1, 64*5*5)\n",
    "        return self.fc1(x)\n",
    "    \n",
    "c = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(c.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Move the model to CUDA\n",
    "c.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_set, epochs : int = 1, device : torch.device = \"cpu\", print_freq : int = 1000):\n",
    "    \"\"\"\n",
    "    Train loop\n",
    "    :param train_set: train dataloader\n",
    "    :param epochs: number of epochs\n",
    "    \"\"\"\n",
    "\n",
    "    loss_values = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_set):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = c(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Save loss for plotting\n",
    "        loss_values.append(running_loss / len(train_set))\n",
    "\n",
    "        model_path = project_directory / f'weights/epoch_{epoch+1}.pth'\n",
    "        torch.save(c.state_dict(), model_path)\n",
    "        print(f'Model saved at epoch {epoch+1}.')\n",
    "\n",
    "    torch.save(c.state_dict(), project_directory / f'weights/final.pth')\n",
    "\n",
    "    # Plot the loss\n",
    "    plt.plot(range(1, epochs + 1), loss_values, marker='o')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.xticks(range(1, epochs + 1))  # Set x-axis ticks to integers only\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.show()\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(train_loader, 3, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Classifier()\n",
    "c.load_state_dict(torch.load(project_directory / f'weights/final.pth'))\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(test_loader, model):\n",
    "    \"\"\"\n",
    "    Get the accuracy of model on test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "\n",
    "get_accuracy(test_loader, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_predictions(model: nn.Module, dataloader: DataLoader) -> List[int]:\n",
    "    \"\"\"\n",
    "    Get predictions from a model for a given dataloader.\n",
    "    :return all_predictions: List of predicted labels for the input data.\n",
    "    \"\"\"\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in dataloader:\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Convert predictions to CPU and numpy for further analysis if needed\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "# Get predictions for the test dataset\n",
    "test_predictions = get_predictions(c, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from typing import List, Optional\n",
    "\n",
    "def plot_confusion_matrices(actual_labels: List[int], predictions: List[int],\n",
    "                             display_log_scaled: Optional[bool] = False) -> None:\n",
    "    \"\"\"\n",
    "    Plot original and log-scaled confusion matrices side by side.\n",
    "\n",
    "    :param actual_labels: ground truth labels for test dataset\n",
    "    :param predictions: predicted labels for test dataste \n",
    "    :param display_log_scaled: flag to also display log-scaled confusion matrix (default is false)\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(actual_labels, predictions)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot the original confusion matrix\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f'Confusion Matrix')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "\n",
    "    # Plot the log-scaled confusion matrix if required\n",
    "    if display_log_scaled:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(np.log1p(cm), annot=True, fmt=\".2f\", cmap=\"Reds\")\n",
    "        plt.title(f'Log-Scaled Confusion Matrix')\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "actual_labels = [label for _, label in test_loader.dataset]\n",
    "test_predictions = get_predictions(c, test_loader)\n",
    "plot_confusion_matrices(actual_labels, test_predictions, display_log_scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "model.load_state_dict(torch.load(project_directory / f'weights/final.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to try FGSM on\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "data, target = batch\n",
    "data.requires_grad = True\n",
    "data.retain_grad = True\n",
    "\n",
    "# Run the original images through the model to get original classifications\n",
    "\n",
    "clean_output = model(data)\n",
    "clean_labels = torch.argmax(clean_output, 1)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()(clean_output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    \"\"\"\n",
    "    Implements the FGSM attack on one image and clamps pixels within valid range\n",
    "    :param image:\n",
    "    :param epsilon:\n",
    "    :param data_grad:\n",
    "    \"\"\"\n",
    "    \n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    \n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configurations for the attack\n",
    "\n",
    "model.zero_grad()\n",
    "loss.backward()\n",
    "data_grad = data.grad.data\n",
    "epsilon = 0.5  # Adjust this value to control the strength of the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the attack\n",
    "\n",
    "perturbed_image = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "perturbed_output = model(perturbed_image)\n",
    "perturbed_labels = torch.argmax(perturbed_output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format and plot images\n",
    "\n",
    "image_np = np.transpose(data.squeeze().detach().numpy(), (1, 2, 0))\n",
    "perturbed_image_np = np.transpose(perturbed_image.squeeze().detach().numpy(), (1, 2, 0))\n",
    "\n",
    "original_images = np.einsum(\"rci -> irc\", image_np)\n",
    "perturbed_images = np.einsum(\"rci -> irc\", perturbed_image_np)\n",
    "\n",
    "fig, axs = plt.subplots(len(original_images), 2, figsize=(4, len(original_images) * 2))\n",
    "\n",
    "for i, (orig, pert, orig_label, pert_label) in enumerate(zip(original_images, perturbed_images, clean_labels, perturbed_labels)):\n",
    "    axs[i, 0].imshow(orig)\n",
    "    axs[i, 0].axis('off')\n",
    "    axs[i, 0].set_title(f'Original Label: {orig_label}')\n",
    "\n",
    "    axs[i, 1].imshow(pert)\n",
    "    axs[i, 1].axis('off')\n",
    "    axs[i, 1].set_title(f'Adversarial Label: {pert_label}')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
