# Repository exploring adversarial attacks on image classification systems
In order to try and understand the practical implementation of adversarial attacks, I have implemented a basic MNIST classifier and a Fast Gradient Sign Method (FGSM) attack on it.

## Resources:
[PyTorch Documentation](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html) - I have followed a similar approach to this guide, but with a different model architecture.